---
title: "UG-Net for Robotic Grasping using Only Depth Image"
authors:
- admin
# - ""
date: "2019-03-05T00:00:00Z"
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: "2019-03-05T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: In IEEE International Conference on Real-time Computing and Robotics 2019
publication_short: In IEEE RCAR 2019

abstract: In this work, we present a real-time, deep convolutional encoder-decoder neural network to realize open-loop robotic grasping using only depth image information. Our proposed U-Grasping fully convolutional neural network(UGNet) predicts the quality and the pose of grasp in pixel-wise. Using only depth information to predict each pixelâ€™s grasp policy overcomes the limitation of sampling discrete grasp candidates which can take a lot of computation time. Our UG-Net improves the grasp quality comparing to other pixelwise grasping learning methods, more robust grasping decision making within 27ms with 370MB parameters approximately (a light competitive version is also given). 

# Summary. An optional shortened abstract.
summary: Our proposed U-Grasping fully convolutional neural network (UGNet) predicts the quality and the pose of grasp in pixel-wise. 

# tags:
# - Source Themes
featured: true

links:
# - name: Custom Link
#   url: http://example.org
url_pdf: http://eprints.soton.ac.uk/352095/1/Cushen-IMV2013.pdf
# url_code: 'https://github.com/aaronhd/pybullet_kinova7.git'
# url_dataset: '#'
# url_poster: '#'
url_project: 'https://github.com/aaronhd/yumipy.git'
# url_slides: ''
# url_source: '#'
url_video: 'https://youtu.be/LJJRqmpYl2c'

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
# - internal-project


# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
# slides: example
---

<!-- {{% alert note %}}
Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /alert %}}

{{% alert note %}}
Click the *Slides* button above to demo Academic's Markdown slides feature.
{{% /alert %}}

Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -->

